{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AMBIGUEDADES DEL LENGUAJE**\n",
    "\n",
    "**Objetivo:** Identificar ambiguedades en el lenguaje de los texto\n",
    "\n",
    "POR AGRUPACIONES DE PALABRAS:\n",
    "- Palabras que pueden tener varios significados\n",
    "- Palabras que pueden tener varios significados y que pueden ser usadas como sustantivo o verbo\n",
    "- Palabras que pueden tener varios significados y que pueden ser usadas como sustantivo o verbo y que pueden ser usadas en diferentes tiempos verbales\n",
    "- Palabras que pueden tener varios significados y que pueden ser usadas como sustantivo o verbo y que pueden ser usadas en diferentes tiempos verbales y que pueden ser usadas en diferentes personas gramaticales\n",
    "\n",
    "FUNCIONAMIENTO:\n",
    "- Se obtienen las palabras que pueden tener varios significados\n",
    "- Se obtienen las palabras que pueden tener varios significados y que pueden ser usadas como sustantivo o verbo\n",
    "\n",
    "LEXICOS:\n",
    "- Se obtienen las palabras que pueden tener varios significados y que pueden ser usadas como sustantivo o verbo y que pueden ser usadas en diferentes tiempos verbales\n",
    "- Se obtienen las palabras que pueden tener varios significados y que pueden ser usadas como sustantivo o verbo y que pueden ser usadas en diferentes tiempos verbales y que pueden ser usadas en diferentes personas gramaticales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema del lenguaje es la ambiguedad y se resuleve con algoritmos de clasificacion con el etiquetado de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cristianmurillo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/cristianmurillo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt') # Tokenizador\n",
    "nltk.download('averaged_perceptron_tagger') # Etiquetador\n",
    "from nltk import word_tokenize, pos_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"they don't permit to others people to get a resident permit.\"\n",
    "tokens = word_tokenize(text)\n",
    "tique = pos_tag(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('they', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('permit', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('others', 'NNS'),\n",
       " ('people', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('resident', 'JJ'),\n",
       " ('permit', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorias gramaticales\n",
    "#nltk.download('tagsets')\n",
    "#nltk.help.upenn_tagset()\n",
    "\n",
    "for l in tique: \n",
    "     print(nltk.help.upenn_tagset(l[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el espa単ol es diferente porque NLTK no tiene algoritmos pre entrenados para espa単ol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     /Users/cristianmurillo/nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('cess_esp')\n",
    "from nltk.corpus import cess_esp as cess\n",
    "from nltk import UnigramTagger as ut\n",
    "from nltk import BigramTagger as bt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/pqhnf_qn3c1g66nvczhrmldw0000gn/T/ipykernel_65007/488303478.py:4: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  uni_tag.evaluate(cess_sents[fraction+1:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8069484240687679"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividimos el corpus en dos partes, 90% para entrenamiento y 10% para prueba\n",
    "# se entrena para que el tagger aprenda a etiquetar en espa単ol usando el corpus cess_esp con unigramas\n",
    "fraction = int(len(cess.tagged_sents()) * 90 / 100)\n",
    "cess_sents = cess.tagged_sents()\n",
    "uni_tag = ut(cess_sents[:fraction])\n",
    "uni_tag.evaluate(cess_sents[fraction+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yo', 'pp1csn00'),\n",
       " ('soy', 'vsip1s0'),\n",
       " ('un', 'di0ms0'),\n",
       " ('hombre', 'ncms000'),\n",
       " ('muy', 'rg'),\n",
       " ('honrado', None),\n",
       " (',', 'Fc'),\n",
       " ('que', 'pr0cn000'),\n",
       " ('me', 'pp1cs000'),\n",
       " ('gusta', 'vmip3s0'),\n",
       " ('lo', 'da0ns0'),\n",
       " ('mejor', 'aq0cs0')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \" Yo soy un hombre muy honrado, que me gusta lo mejor\"\n",
    "tokens = word_tokenize(texto)\n",
    "uni_tag.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/pqhnf_qn3c1g66nvczhrmldw0000gn/T/ipykernel_65007/132087076.py:6: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  big_tag.evaluate(cess_sents[fraction+1:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1095272206303725"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividimos el corpus en dos partes, 90% para entrenamiento y 10% para prueba\n",
    "# se entrena para que el tagger aprenda a etiquetar en espa単ol usando el corpus cess_esp con bigramas\n",
    "fraction = int(len(cess.tagged_sents()) * 90 / 100)\n",
    "cess_sents = cess.tagged_sents()\n",
    "big_tag = bt(cess_sents[:fraction])\n",
    "big_tag.evaluate(cess_sents[fraction+1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yo', 'pp1csn00'),\n",
       " ('soy', 'vsip1s0'),\n",
       " ('un', 'di0ms0'),\n",
       " ('hombre', 'ncms000'),\n",
       " ('muy', 'rg'),\n",
       " ('honrado', None),\n",
       " (',', None),\n",
       " ('que', None),\n",
       " ('me', None),\n",
       " ('gusta', None),\n",
       " ('lo', None),\n",
       " ('mejor', None)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the accuracy of the tagger in bigrams is lower than in unigrams\n",
    "texto2 = \" Yo soy un hombre muy honrado, que me gusta lo mejor\"\n",
    "tokens2 = word_tokenize(texto2)\n",
    "big_tag.tag(tokens2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
