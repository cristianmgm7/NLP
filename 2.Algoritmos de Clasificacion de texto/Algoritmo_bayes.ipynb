{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "clase = []\n",
    "\n",
    "# for spam\n",
    "for file in os.listdir('corpus1/spam/'):\n",
    "    with open('corpus1/spam/' + file, encoding='latin-1') as f:\n",
    "        data.append(f.read())\n",
    "        clase.append('spam')\n",
    "        \n",
    "# for ham\n",
    "for file in os.listdir('corpus1/ham/'):\n",
    "    with open('corpus1/ham/' + file, encoding='latin-1') as f:\n",
    "        data.append(f.read())\n",
    "        clase.append('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "Tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject:', 'what', 'up', ',', ',', 'your', 'cam', 'babe', '\\n', 'what', 'are', 'you', 'looking', 'for', '?', '\\n', 'if', 'your', 'looking', 'for', 'a', 'companion', 'for', 'friendship', ',', 'love', ',', 'a', 'date', ',', 'or', 'just', 'good', 'ole', \"'\", '\\n', 'fashioned', '*', '*', '*', '*', '*', '*', ',', 'then', 'try', 'our', 'brand', 'new', 'site', ';', 'it', 'was', 'developed', 'and', 'created', '\\n', 'to', 'help', 'anyone', 'find', 'what', 'they', \"'\", 're', 'looking', 'for', '.', 'a', 'quick', 'bio', 'form', 'and', 'you', \"'\", 're', '\\n', 'on', 'the', 'road', 'to', 'satisfaction', 'in', 'every', 'sense', 'of', 'the', 'word', '.', '.', '.', '.', 'no', 'matter', 'what', '\\n', 'that', 'may', 'be', '!', '\\n', 'try', 'it', 'out', 'and', 'youll', 'be', 'amazed', '.', '\\n', 'have', 'a', 'terrific', 'time', 'this', 'evening', '\\n', 'copy', 'and', 'pa', 'ste', 'the', 'add', '.', 'ress', 'you', 'see', 'on', 'the', 'line', 'below', 'into', 'your', 'browser', 'to', 'come', 'to', 'the', 'site', '.', '\\n', 'http', ':', '/', '/', 'www', '.', 'meganbang', '.', 'biz', '/', 'bld', '/', 'acc', '/', '\\n', 'no', 'more', 'plz', '\\n', 'http', ':', '/', '/', 'www', '.', 'naturalgolden', '.', 'com', '/', 'retract', '/', '\\n', 'counterattack', 'aitken', 'step', 'preemptive', 'shoehorn', 'scaup', '.', 'electrocardiograph', 'movie', 'honeycomb', '.', 'monster', 'war', 'brandywine', 'pietism', 'byrne', 'catatonia', '.', 'encomia', 'lookup', 'intervenor', 'skeleton', 'turn', 'catfish', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in Tokenizer(data[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    nlp = English()\n",
    "    Tokenizer = Tokenizer(nlp.vocab)\n",
    "    \n",
    "    def tokenize(self, doc):\n",
    "        return [t.text.lower() for t in self.Tokenizer(doc)]\n",
    "    \n",
    "    def word_count(self, words):\n",
    "        word_count = {}\n",
    "        for word in words:\n",
    "            if word in word_count.keys(): # si la palabra ya esta en el diccionario se le suma 1\n",
    "                word_count[word] += 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "        return word_count\n",
    "    \n",
    "    def fit(self, data, clases):\n",
    "        n = len(data)\n",
    "        self.unique_clases = set(clases)\n",
    "        self.vocab = set()\n",
    "        self.class_count = {}\n",
    "        self.log_class_priors = {} # logaritmo de la probabilidad de cada clase\n",
    "        self.word_conditionals = {} # probabilidad de cada palabra en cada clase\n",
    "    # calculo de la probabilidad de cada clase\n",
    "        for clase in clases:\n",
    "            if clase in self.class_count.keys():\n",
    "                self.class_count[clase] += 1\n",
    "            else:\n",
    "                self.class_count[clase] = 1\n",
    "    \n",
    "    # calculo de p(clase)\n",
    "    \n",
    "    for clase in self.class_count.keys():\n",
    "        self.log_class_priors[clase] = math.log(self.class_count[clase] / n)\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
