{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import conll2002\n",
    "from nltk.classify import MaxentClassifier\n",
    "from nltk.tag import ClassifierBasedTagger\n",
    "# importar las bibliotecas necesarias\n",
    "\n",
    "# preparar los datos de entrenamiento y prueba\n",
    "train_sents = list(conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(conll2002.iob_sents('esp.testb'))\n",
    "\n",
    "# definir una función para extraer características de las palabras\n",
    "def word_features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'postag': postag,\n",
    "        'word_is_uppercase': word[0].isupper(),\n",
    "        'word_is_titlecase': word.istitle(),\n",
    "        'word_is_digit': word.isdigit(),\n",
    "        'word_suffix': word[-3:],\n",
    "        'word_prefix': word[:3],\n",
    "        'postag_prefix': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        prev_word = sent[i-1][0]\n",
    "        prev_postag = sent[i-1][1]\n",
    "        features['prev_word'] = prev_word\n",
    "        features['prev_postag'] = prev_postag\n",
    "        features['prev_word_suffix'] = prev_word[-3:]\n",
    "        features['prev_postag_prefix'] = prev_postag[:2]\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        next_word = sent[i+1][0]\n",
    "        next_postag = sent[i+1][1]\n",
    "        features['next_word'] = next_word\n",
    "        features['next_postag'] = next_postag\n",
    "        features['next_word_prefix'] = next_word[:3]\n",
    "        features['next_postag_prefix'] = next_postag[:2]\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    return features\n",
    "\n",
    "# definir una clase para el etiquetador MEMM\n",
    "class MEMMTagger(ClassifierBasedTagger):\n",
    "    def __init__(self, train_sents, feature_detector=word_features, **kwargs):\n",
    "        self.feature_detector = feature_detector\n",
    "        ClassifierBasedTagger.__init__(self, train=train_sents, feature_detector=feature_detector, **kwargs)\n",
    "    def encode_tags(self, tagged_sent):\n",
    "        return [tag for word, tag in tagged_sent]\n",
    "    def decode_tags(self, tags):\n",
    "        return [(word, tag) for (word, _), tag in zip(self.train_sents[0], tags)]\n",
    "    def train(self, train_sents, **kwargs):\n",
    "        self.train_sents = train_sents\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = self.feature_detector(untagged_sent, i)\n",
    "                train_set.append((featureset, tag))\n",
    "        self.classifier = MaxentClassifier.train(train_set, algorithm='megam', **kwargs)\n",
    "\n",
    "# entrenar el modelo MEMM\n",
    "memm_tagger = MEMMTagger(train_sents)\n",
    "\n",
    "# evaluar el modelo en los datos de prueba\n",
    "print(memm_tagger.evaluate(test_sents))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
